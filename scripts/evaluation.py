# -*- coding: utf-8 -*-
"""evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GAZCz93r3VdyXyQJyjlkaa33AjpimOkJ
"""

import numpy as np

# Patch for NumPy 2.0 compatibility (important for older motmetrics)
if not hasattr(np, 'asfarray'):
    np.asfarray = lambda a: np.asarray(a, dtype=np.float64)

import motmetrics as mm
import os

# === 1. Load Ground Truth ===
def read_kitti_gt_file(file_path, obj_type="Car"):
    """
    Reads KITTI ground truth file.
    Filters by object type (e.g., "Car").
    Returns dict: {frame_id: [[track_id, x1, y1, x2, y2], ...]}
    """
    data = {}
    with open(file_path, 'r') as f:
        for line in f:
            fields = line.strip().split()
            frame_id = int(fields[0])
            track_id = int(fields[1])
            type_str = fields[2]
            if type_str != obj_type:
                continue
            bbox = list(map(float, fields[6:10]))
            if frame_id not in data:
                data[frame_id] = []
            data[frame_id].append([track_id] + bbox)
    return data

# === 2. Load Predictions ===
def read_kitti_pred_file(file_path):
    """
    Reads tracking predictions in KITTI format.
    Returns dict: {frame_id: [[track_id, x1, y1, x2, y2], ...]}
    """
    data = {}
    with open(file_path, 'r') as f:
        for line in f:
            fields = line.strip().split()
            frame_id = int(fields[0])
            track_id = int(fields[1])
            bbox = list(map(float, fields[6:10]))
            if frame_id not in data:
                data[frame_id] = []
            data[frame_id].append([track_id] + bbox)
    return data

# === 3. Evaluate using MOT metrics ===
def evaluate_mot(gt_data, pred_data):
    """
    Computes MOT metrics using motmetrics.
    """
    acc = mm.MOTAccumulator(auto_id=True)

    for frame in sorted(gt_data.keys()):
        gt_frame = gt_data.get(frame, [])
        pred_frame = pred_data.get(frame, [])

        gt_ids = [g[0] for g in gt_frame]
        gt_boxes = [g[1:] for g in gt_frame]

        pred_ids = [p[0] for p in pred_frame]
        pred_boxes = [p[1:] for p in pred_frame]

        # Compute IoU distance matrix
        distances = mm.distances.iou_matrix(gt_boxes, pred_boxes, max_iou=0.5)
        acc.update(gt_ids, pred_ids, distances)

    # Compute and print summary
    mh = mm.metrics.create()
    summary = mh.compute(acc, metrics=mm.metrics.motchallenge_metrics, name='summary')

    # Print readable results
    print(mm.io.render_summary(summary, formatters=mh.formatters, namemap=mm.io.motchallenge_metric_names))

# === 4. Run Evaluation ===
if __name__ == "__main__":
    gt_file = '/content/drive/MyDrive/kitti_tracking/data_tracking_label_2/training/label_02/0000.txt'
    pred_file = '/content/ByteTrack/results/0000.txt'

    assert os.path.exists(gt_file), f"GT file not found: {gt_file}"
    assert os.path.exists(pred_file), f"Prediction file not found: {pred_file}"

    gt_data = read_kitti_gt_file(gt_file, obj_type="Car")
    pred_data = read_kitti_pred_file(pred_file)

    evaluate_mot(gt_data, pred_data)